# -*- coding: utf-8 -*-
"""SUBMISSION ML TERAPAN AKHIR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HppB3jxdb87Jzlt4ixpuRvCijwx74IZ3

# **Sistem Rekomendasi Tempat Wisata**

# **Data Loading**

Tahapan ini digunakan untuk mengunduh dataset dari Kaggle ke Google Colab. File kaggle.json diunggah untuk autentikasi, lalu digunakan untuk mengakses dan mengunduh dataset Indonesia Tourism Destination, yang kemudian diekstrak agar siap digunakan.
"""

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d aprabowo/indonesia-tourism-destination

!unzip indonesia-tourism-destination.zip

"""# **Data Understanding**"""

import pandas as pd

df_places = pd.read_csv('tourism_with_id.csv')
df_ratings = pd.read_csv('tourism_rating.csv')

print('Total lokasi unik:', df_places['Place_Id'].nunique())
print('Total penilaian yang tercatat:', df_ratings['Place_Ratings'].shape[0])

"""Tahapan diatas memuat dua dataset dan menampilkan ringkasan awal. Hasilnya menunjukkan terdapat 437 lokasi wisata unik dan 10.000 data penilaian.

## Univariate Exploratory Data Analysis (EDA)
"""

df_places.info()

"""Output diatas menampilkan informasi struktur dataset df_places yang berisi 437 data lokasi wisata dengan 13 kolom. Diketahui beberapa kolom seperti Time_Minutes memiliki nilai kosong, dan dua kolom (Unnamed: 11 dan Unnamed: 12) tampak tidak relevan karena kosong atau tidak bermakna."""

df_places.sample(5)

"""Sampel data dari df_places menunjukkan informasi berbagai tempat wisata seperti Taman Pelangi, Pantai Kukup, hingga Taman Vanda. Setiap entri mencakup detail seperti nama, deskripsi, kategori (misalnya Taman Hiburan atau Bahari), kota, harga, rating, estimasi waktu kunjungan, serta koordinat lokasi dalam bentuk lat dan long. Terlihat pula bahwa kolom Unnamed: 11 tidak berisi data."""

df_places.describe()

"""Hasil statistik deskriptif dari df_places menunjukkan bahwa terdapat 437 tempat wisata dengan rata-rata harga tiket sekitar Rp24.652 dan rating rata-rata 4.44 dari skala 5. Waktu kunjungan yang tercatat pada sebagian data memiliki rata-rata 82 menit. Lokasi tersebar di koordinat lintang antara -8.20 hingga 1.08 dan bujur antara 103.93 hingga 112.82. Kolom Unnamed: 11 sepenuhnya kosong."""

df_ratings.info()

"""Data df_ratings terdiri dari 10.000 entri yang mencatat interaksi antara pengguna (User_Id) dan tempat wisata (Place_Id) dalam bentuk penilaian (Place_Ratings). Seluruh kolom terisi lengkap tanpa nilai kosong, dengan tipe data numerik (int64), menandakan dataset ini bersih dan siap digunakan untuk analisis sistem rekomendasi."""

df_ratings.sample(5)

"""Sample data df_ratings menunjukkan beberapa pengguna memberikan penilaian terhadap tempat wisata tertentu. Misalnya, pengguna dengan User_Id 72 memberi rating 4 untuk tempat dengan Place_Id 404. Nilai rating ini berkisar dari 1 hingga 5."""

df_ratings.describe()

"""Berdasarkan statistik deskriptif dari df_ratings, terdapat 10.000 data penilaian yang diberikan oleh 300 pengguna (User_Id maksimum 300) terhadap 437 tempat wisata. Rata-rata rating yang diberikan adalah sekitar 3.07, dengan rating minimum 1 dan maksimum 5. Mayoritas pengguna memberikan rating antara 2 hingga 4, yang menunjukkan distribusi penilaian cukup merata.

# **Data Preparation**
"""

df_places.drop(columns=['Description', 'City', 'Price', 'Rating', 'Time_Minutes', 'Coordinate', 'Lat', 'Long', 'Unnamed: 11', 'Unnamed: 12'], inplace=True)

"""Kode tersebut menghapus beberapa kolom spesifik dari DataFrame df_places secara permanen, yaitu kolom 'Description', 'City', 'Price', 'Rating', 'Time_Minutes', 'Coordinate', 'Lat', 'Long', serta dua kolom tak bernama ('Unnamed: 11' dan 'Unnamed: 12')."""

print("Missing values pada places:\n", df_places.isna().sum())

"""Kode tersebut mencetak jumlah nilai yang hilang (missing values) pada setiap kolom di DataFrame df_places. Hasilnya menunjukkan bahwa tidak ada data yang hilang di kolom Place_Id, Place_Name, maupun Category."""

print("Missing values pada ratings:\n", df_ratings.isna().sum())

"""Kode tersebut menampilkan jumlah nilai yang hilang (missing values) pada setiap kolom di DataFrame df_ratings. Hasilnya menunjukkan bahwa kolom User_Id, Place_Id, dan Place_Ratings semuanya tidak memiliki nilai yang hilang."""

print("Data duplikat pada places:", df_places.duplicated().sum())

"""Kode tersebut mengecek dan menghitung jumlah baris data duplikat di DataFrame df_places. Hasilnya menunjukkan tidak ada data yang duplikat, alias jumlahnya nol."""

print("Data duplikat pada ratings:", df_ratings.duplicated().sum())

"""Kode tersebut menghitung jumlah baris data duplikat di DataFrame df_ratings. Hasilnya menunjukkan ada 79 baris yang merupakan data duplikat."""

df_ratings.drop_duplicates(inplace=True)

"""Kode tersebut menghapus semua baris duplikat secara permanen dari DataFrame df_ratings, sehingga hanya menyisakan data unik saja.

# **Modelling**

## Model Development dengan Content-based

### TF-IDF Vectorizer
"""

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer()
vectorizer.fit(df_places['Category'])

fitur_kategori = vectorizer.get_feature_names_out()

matrix_tfidf = vectorizer.fit_transform(df_places['Category'])

print("Ukuran matriks TF-IDF:", matrix_tfidf.shape)

"""Kode tersebut menggunakan TfidfVectorizer dari scikit-learn untuk mengubah teks kategori di kolom Category menjadi representasi numerik berbasis TF-IDF. Setelah mempelajari data teks kategori, kode menghasilkan matriks TF-IDF dengan ukuran 437 baris (jumlah data) dan 10 kolom (fitur unik kategori)."""

dense_tfidf = matrix_tfidf.todense()

pd.DataFrame(
    dense_tfidf,
    columns=fitur_kategori,
    index=df_places['Place_Name']
).sample(10)

"""Kode tersebut mengubah matriks TF-IDF yang awalnya dalam format sparse menjadi matriks dense (penuh), lalu mengubahnya menjadi DataFrame dengan kolom fitur kategori dan indeks nama tempat (Place_Name). Selanjutnya, kode menampilkan 10 sampel baris acak yang menunjukkan bobot TF-IDF tiap kategori untuk beberapa tempat wisata.

### Cosine Similarity
"""

from sklearn.metrics.pairwise import cosine_similarity

similarity_matrix = cosine_similarity(matrix_tfidf)

df_similarity = pd.DataFrame(
    similarity_matrix,
    index=df_places['Place_Name'],
    columns=df_places['Place_Name']
)

print("Dimensi DataFrame cosine similarity:", df_similarity.shape)

"""Kode tersebut menghitung kemiripan antar tempat wisata berdasarkan kategori menggunakan cosine similarity dari matriks TF-IDF. Hasilnya berupa matriks persegi 437x437 yang menunjukkan tingkat kesamaan setiap tempat dengan tempat lainnya, lalu disimpan dalam DataFrame dengan indeks dan kolom nama tempat wisata."""

df_similarity.sample(10)

"""Tabel diatas menampilkan 10 baris acak dari DataFrame kemiripan cosine antar tempat wisata, di mana setiap nilai menunjukkan seberapa mirip dua tempat berdasarkan kategori mereka. Nilai 1 berarti kategori sama persis, sedangkan 0 berarti tidak ada kesamaan kategori antara dua tempat tersebut.

### Testing
"""

def rekomendasi_tempat(nama_tempat, similarity_df=df_similarity, data=df_places[['Place_Name', 'Category']], jumlah=5):
    idx = similarity_df.loc[:, nama_tempat].to_numpy().argpartition(range(-1, -jumlah, -1))
    rekomendasi_terdekat = similarity_df.columns[idx[-1:-(jumlah+2):-1]]
    rekomendasi_terdekat = rekomendasi_terdekat.drop(nama_tempat, errors='ignore')
    return pd.DataFrame(rekomendasi_terdekat).merge(data).head(jumlah)

target_tempat = 'Monumen Nasional'
df_places[df_places['Place_Name'] == target_tempat]

rekomendasi_tempat(target_tempat)

"""Fungsi rekomendasi_tempat memberikan rekomendasi tempat wisata serupa berdasarkan kemiripan kategori dengan tempat yang dipilih (nama_tempat). Fungsi ini mencari sejumlah tempat dengan skor kemiripan tertinggi dari matriks cosine similarity, lalu mengembalikan daftar nama tempat beserta kategorinya. Contohnya, untuk target "Monumen Nasional," fungsi merekomendasikan lima tempat wisata lain yang juga bertema budaya dan memiliki kategori serupa.

## Model Development dengan Collaborative Filtering

### Data Preparation
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt

unique_user_ids = df_ratings['User_Id'].unique().tolist()

user_mapping = {user_id: idx for idx, user_id in enumerate(unique_user_ids)}
reverse_user_mapping = {idx: user_id for user_id, idx in user_mapping.items()}

unique_place_ids = df_ratings['Place_Id'].unique().tolist()
place_mapping = {place_id: idx for idx, place_id in enumerate(unique_place_ids)}
reverse_place_mapping = {idx: place_id for place_id, idx in place_mapping.items()}

df_ratings['user'] = df_ratings['User_Id'].map(user_mapping)
df_ratings['place'] = df_ratings['Place_Id'].map(place_mapping)
df_ratings['rating'] = df_ratings['Place_Ratings'].astype(np.float32)

"""Kode tersebut menyiapkan data df_ratings untuk model pembelajaran mesin dengan melakukan pemetaan ID pengguna dan tempat wisata ke indeks numerik yang berurutan, sehingga lebih mudah digunakan dalam pemodelan. Kolom baru user dan place berisi indeks tersebut, sementara kolom rating diubah tipe datanya menjadi float32 untuk kompatibilitas dengan TensorFlow."""

total_users = len(user_mapping)
total_places = len(place_mapping)

rating_min = df_ratings['rating'].min()
rating_max = df_ratings['rating'].max()

print(f'Jumlah Pengguna: {total_users}')
print(f'Jumlah Tempat: {total_places}')
print(f'Rating Minimum: {rating_min}')
print(f'Rating Maksimum: {rating_max}')

"""Kode tersebut menghitung dan menampilkan total jumlah pengguna (300), total tempat wisata (437), serta rentang nilai rating dari data, mulai dari minimum 1.0 hingga maksimum 5.0. Informasi ini berguna untuk memahami ukuran dataset dan skala rating sebelum membangun model rekomendasi.

### Split Data Latih & Data Uji
"""

ratings = df_ratings.sample(frac=1, random_state=42)

fitur = ratings[['user', 'place']].values
target = ratings['rating'].apply(lambda r: (r - rating_min) / (rating_max - rating_min)).values

batas_data_latih = int(0.8 * len(ratings))
x_train, x_val = fitur[:batas_data_latih], fitur[batas_data_latih:]
y_train, y_val = target[:batas_data_latih], target[batas_data_latih:]

print(fitur, target)

"""Kode tersebut mengacak data rating, kemudian menyiapkan fitur input berupa pasangan indeks pengguna dan tempat (user, place) serta target rating yang sudah dinormalisasi ke rentang 0 hingga 1. Selanjutnya, data dibagi menjadi data latih (80%) dan validasi (20%). Output menunjukkan contoh fitur dan target yang telah disiapkan untuk model.

### Model Development
"""

class ModelRekomendasi(tf.keras.Model):
    def __init__(self, total_user, total_place, dimensi_embedding, **kwargs):
        super(ModelRekomendasi, self).__init__(**kwargs)
        self.user_embedding = layers.Embedding(
            input_dim=total_user,
            output_dim=dimensi_embedding,
            embeddings_initializer='he_normal',
            embeddings_regularizer=keras.regularizers.l2(1e-8)
        )
        self.user_bias = layers.Embedding(total_user, 1)

        self.place_embedding = layers.Embedding(
            input_dim=total_place,
            output_dim=dimensi_embedding,
            embeddings_initializer='he_normal',
            embeddings_regularizer=keras.regularizers.l2(1e-8)
        )
        self.place_bias = layers.Embedding(total_place, 1)

    def call(self, input_data):
        user_vec = self.user_embedding(input_data[:, 0])
        user_bias = self.user_bias(input_data[:, 0])
        place_vec = self.place_embedding(input_data[:, 1])
        place_bias = self.place_bias(input_data[:, 1])

        dot_interaksi = tf.tensordot(user_vec, place_vec, axes=2)
        output = dot_interaksi + user_bias + place_bias
        return tf.nn.sigmoid(output)

"""Kelas ModelRekomendasi adalah model deep learning berbasis TensorFlow yang menggunakan embedding untuk mempelajari representasi vektor pengguna dan tempat wisata. Model ini mengalikan vektor embedding pengguna dan tempat (dot product) dan menambahkan bias masing-masing untuk memprediksi rating yang dinormalisasi. Output akhir diproses dengan fungsi sigmoid agar nilai prediksi berada di rentang 0 sampai 1, cocok untuk data rating yang sudah dinormalisasi."""

model = ModelRekomendasi(total_users, total_places, 64)

model.compile(
    loss=keras.losses.BinaryCrossentropy(),
    optimizer=keras.optimizers.Adam(learning_rate=0.0001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""Kode ini membuat instance ModelRekomendasi dengan dimensi embedding 64, lalu mengompilasi model menggunakan fungsi loss Binary Crossentropy, optimizer Adam dengan learning rate 0.0001, dan metrik evaluasi Root Mean Squared Error (RMSE). Setup ini mempersiapkan model untuk pelatihan prediksi rating yang dinormalisasi."""

from keras.callbacks import EarlyStopping
early_stop = EarlyStopping(
    patience=5,
    min_delta=0.0001,
    restore_best_weights=True
)

"""Kode ini membuat callback EarlyStopping untuk menghentikan pelatihan model secara otomatis jika metrik validasi tidak membaik selama 5 epoch berturut-turut (patience=5) dengan perbaikan minimal 0.0001. Selain itu, model akan mengembalikan bobot terbaik yang ditemukan selama pelatihan (restore_best_weights=True), mencegah overfitting dan menghemat waktu pelatihan."""

history = model.fit(
    x=x_train,
    y=y_train,
    batch_size=16,
    epochs=25,
    validation_data=(x_val, y_val),
    callbacks=[early_stop]
)

"""Model ModelRekomendasi dilatih selama 24 epoch dengan batch size 16, menggunakan data training dan validasi. Loss fungsi yang dipakai adalah Binary Crossentropy, dan metrik yang dipantau adalah Root Mean Squared Error (RMSE).
Pada awal pelatihan, loss dan RMSE di data training dan validasi relatif tinggi dan hanya mengalami penurunan yang sangat kecil.
"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('Root Mean Squared Error Model')
plt.xlabel('Epoch')
plt.ylabel('RMSE')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

"""Kode tersebut menampilkan grafik Root Mean Squared Error (RMSE) selama pelatihan model. Grafik menunjukkan bahwa RMSE pada data training terus menurun, sedangkan RMSE pada data validation cenderung stabil. Ini mengindikasikan bahwa model belajar dengan baik pada data pelatihan, namun kurang mengalami peningkatan pada data validasi, yang bisa menjadi tanda awal overfitting."""

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss Model')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

"""Kode tersebut memvisualisasikan nilai loss pada data pelatihan dan validasi selama epoch. Grafik menunjukkan bahwa loss pada data pelatihan terus menurun, sedangkan loss validasi relatif datar. Hal ini mengindikasikan model belajar dari data pelatihan, tetapi tidak menunjukkan perbaikan signifikan pada data validasi, yang dapat mengarah pada potensi overfitting.

### Testing
"""

place_df = df_places
ratings_df = df_ratings

random_user = ratings_df.User_Id.sample(1).iloc[0]
user_rated = ratings_df[ratings_df.User_Id == random_user]

unrated_places = place_df[~place_df['Place_Id'].isin(user_rated.Place_Id.values)]['Place_Id']
unrated_places = list(set(unrated_places).intersection(place_mapping.keys()))

encoded_unrated = [[place_mapping[x]] for x in unrated_places]
encoded_user = user_mapping.get(random_user)

user_input_array = np.hstack(([[encoded_user]] * len(encoded_unrated), encoded_unrated))

predicted_scores = model.predict(user_input_array).flatten()
top_idx = predicted_scores.argsort()[-10:][::-1]

recommended_ids = [reverse_place_mapping[encoded_unrated[i][0]] for i in top_idx]

"""Kode tersebut melakukan rekomendasi tempat wisata untuk satu pengguna secara acak dengan cara memilih satu pengguna secara acak dari data rating, lalu diambil daftar tempat yang belum pernah dinilai oleh pengguna tersebut. Selanjutnya, tempat-tempat yang belum dinilai tersebut diubah ke format indeks sesuai pemetaan, dan dibuat array input yang berisi pasangan user dan tempat untuk diprediksi ratingnya oleh model. Setelah itu, model memprediksi skor rating untuk semua tempat yang belum dinilai, dan 10 tempat dengan skor tertinggi dipilih sebagai rekomendasi untuk pengguna tersebut."""

import pandas as pd

print(f"Rekomendasi untuk user: {random_user}")
print("=" * 50)

top_rated = user_rated.sort_values(by='rating', ascending=False).head(5)['Place_Id'].values
top_rated_df = place_df[place_df['Place_Id'].isin(top_rated)][['Place_Name', 'Category']]
top_rated_df.insert(0, 'No', range(1, len(top_rated_df) + 1))
print("Tempat yang pernah diberi rating tinggi:")
display(top_rated_df)

"""Kode tersebut menampilkan rekomendasi untuk pengguna dengan ID 193. Pertama, dicetak informasi tentang user tersebut, lalu ditampilkan 5 tempat yang pernah diberi rating tertinggi oleh user tersebut, lengkap dengan nama tempat dan kategori. Tampilan ini membantu memahami preferensi pengguna sebelum memberikan rekomendasi tempat baru."""

# Tempat rekomendasi
recommended_df = place_df[place_df['Place_Id'].isin(recommended_ids)][['Place_Name', 'Category']]
recommended_df.insert(0, 'No', range(1, len(recommended_df) + 1))
print("\n10 Rekomendasi Tempat Terbaik:")
display(recommended_df)

"""Kode tersebut menampilkan daftar 10 tempat rekomendasi terbaik untuk pengguna tersebut, berupa tabel yang berisi nomor urut, nama tempat, dan kategori tempat. Rekomendasi ini diambil berdasarkan prediksi model terhadap tempat-tempat yang belum pernah dikunjungi atau diberi rating oleh user, sehingga memberikan opsi baru yang sesuai dengan preferensi pengguna.

# **Kesimpulan**

Kesimpulan dari keseluruhan proses dan kode ini adalah pembuatan sistem rekomendasi wisata yang menggabungkan pendekatan collaborative filtering dengan embedding menggunakan model deep learning. Sistem ini memetakan pengguna dan tempat wisata ke dalam ruang vektor berdimensi embedding, lalu memprediksi preferensi pengguna terhadap tempat-tempat yang belum pernah mereka nilai berdasarkan interaksi sebelumnya (rating). Data rating pengguna diolah dan dinormalisasi untuk pelatihan model, yang kemudian digunakan untuk merekomendasikan tempat baru dengan prediksi skor tertinggi. Selain itu, sistem menampilkan riwayat tempat yang disukai pengguna sebagai referensi. Pendekatan ini efektif dalam memberikan rekomendasi personal yang relevan dengan preferensi individu, memanfaatkan pola kolektif dari data pengguna lain, serta menyesuaikan rekomendasi sesuai minat spesifik pengguna.
"""